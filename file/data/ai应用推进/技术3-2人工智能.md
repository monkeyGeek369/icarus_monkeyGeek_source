# 大语言模型（LLM）理论与应用

### Transformer架构详解

- 为什么要抛弃RNN/CNN
   - 存在致命缺陷
      - 顺序计算，无法并行： RNN 必须一步一步处理序列，`t` 时刻的计算依赖于 `t-1` 时刻的结果。这就像流水线，无法同时开工，训练速度极慢。
      - 长程依赖问题： 虽然 LSTM 有所改善，但当序列非常长时，模型依然难以记住远距离的信息。信息在一步步传递中会逐渐衰减或变形。
   - Transformer的解决方案：
      - 完全并行： 抛弃递归，整个序列同时输入，同时计算
      - 自注意力机制： 让序列中的任何一个词都能直接与所有其他词（无论多远）进行交互,即得到与其它词的关系
   - 核心比喻
      - RNN/LSTM： 像一个人逐字阅读一篇文章，阅读后文时，需要努力回忆前文的内容。
      - Transformer： 像一个人拥有了“瞬间通读”全文的超能力，在理解任何一个词时，他能瞬间看到并权衡文章中所有其他词对这个词的影响。
- 宏观架构：Encoder-Decoder 框架
   - 编码器（Encoder）：
     - 任务： 理解和“编码”输入序列（如一句英文），将其转化为一个富含上下文信息的中间表示（一组高维向量）。
     - 结构： 由 N 个（原论文中 N=6）完全相同的 编码器层 堆叠而成。
     - Encoder-only（如 BERT、ERNIE）：双向编码，擅长理解类任务（政务文本分类、实体识别），适合需要深度解析政务文本语义的场景
   - 解码器（Decoder）：
     - 任务： 根据编码器的输出和已经生成的输出序列，自回归地（一个接一个地）“解码”出目标序列（如对应的中文）。
     - 结构： 同样由 N 个 完全相同的 解码器层 堆叠而成
     - Decoder-only（如 GPT、Llama 3、Qwen）：自回归生成，擅长生成类任务（政务问答、政策摘要），是当前政务 LLM 应用的主流架构，适配交互性强的政务服务场景。。
   - 工作流程（以机器翻译为例）：
      - 编码： 输入句子 “I love China” 进入编码器，被编码成一个富含语义的矩阵。
      - 解码： 解码器开始工作。给定一个起始符 `<start>`，它结合编码器的输出，预测第一个词 “我”。
      - 然后将 `<start>, “我”` 作为输入，结合编码器输出，预测下一个词 “爱”。
      - 接着将 `<start>, “我”, “爱”` 作为输入，预测下一个词 “中国”。
      - 最后预测出结束符 `<end>`，生成过程结束。
- 自注意力机制
   - 核心思想
      - 自注意力机制的目的是为序列中的每个词计算一个 “新的表示”，这个表示是所有其他词的表示的加权平均。权重由词与词之间的“相关性”决定。
   - 三步走理解计算过程：对于输入序列中的每个词向量，我们将其分别乘以三个矩阵，得到三个新的向量：
      - Q（查询）： “我要去寻找其他词中哪些与我相关。”
      - K（键）： “我是其他词的一个标签，等着被查询。”
      - V（值）： “我真正要贡献的信息内容。”
   - 计算步骤：
      1. 计算注意力分数： 用一个词的 Q 去点乘所有词的 K。分数越高，表示这两个词越相关。
      2. 缩放与 Softmax：
         - 缩放： 将分数除以 `√(dk)`（`dk` 是 K 的维度）。目的是在 Softmax 之前稳定梯度，防止点积结果过大导致梯度消失。
         - Softmax： 将分数转换为概率分布（和为1），这就是注意力权重。它代表了在计算当前词的新表示时，应该“关注”其他每个词的程度。
      3. 加权求和： 将上一步得到的注意力权重，与所有词的 V 向量相乘并求和。得到的结果就是当前词新的、融入了全局上下文信息的表示
   - 一个绝佳的比喻：想象你在一个图书馆（输入序列）查资料。
      - Q（你的问题）： “我想找关于深度学习和烹饪的书。”
      - K（书的索引卡）： 每本书的索引卡上写着它的主题。
      - V（书的内容）： 书本身的内容。
        你（Q）会去和所有书的索引卡（K）进行比较（点乘），发现“深度学习”和“烹饪”这两本书的索引卡与你的问题最匹配（分数高）。然后你根据这个匹配程度（注意力权重），从“深度学习”书中摘录一些段落，从“烹饪”书中摘录一些段落（加权求和 V），最终组合成一份满足你需求的答案（新的表示）。
- 多头注意力
   - 思想:只做一次自注意力，可能只学到一种模式的关系（例如语法关系）。我们让模型同时进行多次（原论文是8次）自注意力计算，每次使用不同的可学习投影矩阵，从而将 Q、K、V 投影到不同的“表示子空间”。
   - 好处： 模型可以同时关注来自不同位置的不同类型的信息。比如，一个头关注语法结构，一个头关注指代关系，另一个头关注情感基调等。最后将所有头的输出拼接起来，再投影回原始维度。
- 位置编码
   - 问题： 自注意力机制本身是置换不变的，它完全不知道词的顺序。`“猫吃鱼”` 和 `“鱼吃猫”` 对它来说输入是一样的。
   - 解决方案： 在将词向量输入编码器/解码器之前，为每个词向量加上一个位置编码。这个编码包含了该词在序列中的位置信息。
   - 实现： 使用不同频率的正弦和余弦函数来生成独一无二的位置编码向量。这样模型就能利用序列的顺序信息了。
- 残差连接与层归一化
   - 残差连接： 将子层的输入直接加到其输出上,缓解深层网络中的梯度消失问题，让模型更容易训练深达数十甚至上百层的网络。
   - 层归一化： 对每个样本的所有特征维度进行归一化，使其均值为0，方差为1。稳定训练过程，加速收敛。
- 位置前馈网络
   - 每个编码器/解码器层中，在自注意力层之后，都有一个相同的前馈神经网络。它由两个线性变换和一个 ReLU 激活函数组成：`FFN(x) = max(0, xW1 + b1)W2 + b2`。
   - 特点： 它对序列中的每个位置独立、相同地应用。它的作用是对自注意力层输出的表示进行进一步的非线性变换和维度调整。
- 解码器的特殊之处
   1. 掩码自注意力：
      - 问题： 在训练时，解码器不应该“偷看”未来的答案。在预测第 `t` 个词时，它只能使用 `1` 到 `t-1` 时刻的信息。
      - 解决方案： 在解码器的第一个自注意力层中，通过一个注意力掩码，将当前位置之后的所有位置都遮盖掉（设置为负无穷），这样在计算 Softmax 时，这些位置的权重就变成了 0。
   2. 编码器-解码器注意力：
      - 解码器的第二个注意力层不再是“自”注意力。它的 K 和 V 来自编码器的最终输出，而 Q 来自解码器上一层的输出。
      - 作用： 这让解码器在生成每一个词时，都能有选择地关注输入序列中最相关的部分。这非常符合机器翻译等任务的直觉：在生成目标语言的某个词时，我们会回头去源语言句子中寻找对应的信息。
- 总结与常考问题
   - “Transformer 是为了解决 RNN 的并行性和长程依赖问题而提出的。它的核心是自注意力机制，通过 Q、K、V 的计算，让序列中的每个词都能直接与所有词交互，生成一个包含全局上下文的表示。为了增强模型能力，它使用了多头注意力来捕捉不同类型的关系。由于自注意力没有位置信息，它引入了正弦余弦位置编码。整个架构是 Encoder-Decoder 模式，通过堆叠多层来增加模型的表达能力，并用残差连接和层归一化来稳定深层网络的训练。解码器则通过掩码自注意力防止信息泄露，并通过编码器-解码器注意力来获取源序列的信息。”
- 什么是MoE架构
   - 其核心思想是“不是所有参数都对每个输入都起作用”，而是根据输入动态地选择激活一部分子网络（称为“专家”），从而在保持模型容量（capacity）的同时控制计算成本



### MLOps/LLMOps流程与工具链

- 什么是 MLOps？
   - 标准化和简化机器学习系统的构建、部署和维护流程
- MLOps 的核心流程（生命周期）
   1. 问题定义与数据管理
      - 任务：明确业务目标，确定数据来源。
      - 内容：数据收集、数据清洗、数据标注、数据版本控制、特征存储。
   2. 模型开发与实验
      - 任务：进行特征工程，选择算法，训练模型，进行超参数调优。
      - 内容：实验跟踪、代码版本控制、模型评估。
   3. 模型交付与部署
      - 任务：将训练好的模型打包，并部署到生产环境。
      - 内容：模型打包（Docker）、模型注册、持续集成/持续部署（CI/CD）、A/B测试、影子部署。
   4. 监控与运维
      - 任务：监控生产环境中模型的性能和数据分布，确保其稳定运行。
      - 内容：性能监控（准确率、延迟）、数据漂移监控、概念漂移监控、日志记录、自动化告警与回滚。
   5. 迭代优化
      - 任务：根据监控反馈，触发模型的重新训练或整个流程的重新开始。
      - 内容：自动化重新训练管道。
- 什么是 LLMOps？
   - LLMOps 是在 MLOps 基础上，专门针对大语言模型的应用和微调场景衍生出的实践体系。

| 特性       | MLOps（传统机器学习）  | LLMOps（大语言模型）                       |
| :--------- | :--------------------- | :----------------------------------------- |
| 模型来源   | 主要从零开始训练或微调 | 主要基于预训练的基础模型进行微调或直接调用 |
| 核心输入   | 特征向量               | 提示词、上下文                             |
| 核心流程   | 特征工程、模型训练     | 提示词工程、RAG、微调                      |
| 部署单元   | 模型本身               | 模型 + 提示词模板 + 向量数据库 + 推理引擎  |
| 评估标准   | 准确率、F1分数等       | 人工或LLM评估、相关性、忠实度、无害性等    |
| 成本与资源 | 相对较低               | 极高（训练和推理）                         |

- LLMOps 的核心流程
   1. 数据准备与提示工程
      - 准备用于微调的数据集（指令-回答对）设计和迭代提示词模板。
   2. 模型选择与接入
   3. 微调与优化
      - 使用LoRA、QLoRA等参数高效微调技术,进行RAG 系统的构建：文档切分、向量化、检索。
   4. 评估与测试
   5. 部署与 Serving
   6. 监控与治理
- 概念理解类
   1. MLOps/LLMOps的核心价值与目标是什么？
      - 提高机器学习项目的效率、可复现性、可靠性和自动化水平，缩短从实验到生产的周期，确保模型在生产环境的持续健康和价值。
   2. MLOps 与 DevOps 的区别与联系？
      - 联系：都强调CI/CD、自动化、监控和协作。
      - 区别：MLOps需要额外管理数据和模型这两个动态且不断演变的资产，而DevOps主要管理代码。ML流程具有更强的实验性。
   3. LLMOps 与 MLOps 的主要区别是什么？
      - 强调提示词 vs 特征工程、微调/RAG vs 从零训练、评估方式的差异以及极高的资源成本。
- 流程与技术类
   2. 什么是数据漂移和概念漂移？如何监控？
      - 数据漂移：输入数据的分布发生变化。（例如，用户画像特征分布变了）
      - 概念漂移：输入特征和输出目标之间的关系发生变化。（例如，疫情前后“购物”和“收入”的关系变了）
      - 监控工具：Evidently AI， Amazon SageMaker Model Monitor， Azure Machine Learning 漂移检测。
   3. 模型版本控制需要注意什么？除了代码，还需要对什么进行版本控制？
      - 需要版本控制的要素：代码、数据（如DVC）、模型文件（如MLflow Model Registry）、环境（Docker镜像）、配置文件。
   4. 在LLMOps中，RAG和微调分别适用于什么场景？
      - RAG：适用于知识密集型任务，需要模型具备特定领域/私有知识，且知识需要频繁更新的场景。成本较低，实现较快。
      - 微调：适用于改变模型风格、格式，或学习一种新的复杂任务范式。成本高，但对模型底层能力影响更深。
   5. 如何评估一个RAG系统的好坏？
      - 参考答案：可以从检索质量（召回率、准确率）、生成质量（相关性、忠实度、流畅度）以及端到端指标（回答正确率）等多维度评估。RAGAS是一个专门用于此的工具。
- 工具链类
   1. 请说出几个流行的MLOps/LLMOps工具，并说明其用途。
      - 实验跟踪：MLflow， Weights & Biases
      - 工作流编排：Airflow， Kubeflow Pipelines， Prefect， Dagster
      - 模型部署与Serving：KServe， Seldon Core， Triton Inference Server， vLLM（专用于LLM）
      - 模型注册中心：MLflow Model Registry
      - 数据版本控制：DVC， Delta Lake
      - 向量数据库：Pinecone， Weaviate， Qdrant， Chroma（用于RAG）
      - LLM应用框架：LangChain， LlamaIndex
      - 监控：Evidently AI， Arize AI， WhyLabs
   2. MLflow 主要由哪几个组件构成？
      - Tracking：记录实验参数、指标和产物。
      - Projects：打包可复现的代码。
      - Models：打包模型，并提供多种部署方式。
      - Model Registry：中心化的模型存储、版本管理和生命周期管理。
   3. 在Kubernetes上部署模型服务有哪些选择？
      - 参考答案：KServe（推荐）、Seldon Core、NVIDIA Triton Inference Server。它们都提供了Kubernetes原生API，可以轻松实现扩缩容、金丝雀发布等。
- 场景与实践类
   1. 如果生产环境的模型性能突然下降，你的排查思路是什么？
      - 检查监控指标：确认是数据漂移、概念漂移还是服务本身（如延迟增高、错误率上升）的问题。
      - 检查数据：对比当前输入数据与训练数据分布的差异。
      - 检查日志：查看推理服务是否有异常。
      - 回滚模型：如果怀疑是新模型问题，立即回滚到上一个稳定版本。
      - 触发重新训练：根据分析结果，触发自动化重新训练管道。
   2. 设计一个支持A/B测试的模型部署方案。
      - 使用模型注册中心管理A/B版本，通过服务网格或特性网关将流量按一定比例（如90/10）路由到不同的模型服务（如部署在KServe上的两个推理服务），最后收集并对比两者的业务指标。
   3. 在LLM应用中，如何控制成本和优化性能？
      - 成本：监控Token使用量；对非实时任务使用小模型或更低成本的API；使用缓存（缓存频繁出现的提示词-回答对）。
      - 性能：使用vLLM等高性能推理引擎；使用量化技术；优化提示词长度；在RAG中优化检索Top-K数量。



### 主流LLM模型介绍

- DeepSeek（深度求索）
   - 代表模型：DeepSeek-V2、DeepSeek-Coder、DeepSeek-MoE。
   - 基于 MoE（Mixture of Experts）架构（如 DeepSeek-V2），支持高效推理。训练数据涵盖大量中英文代码、技术文档、通用语料，特别强调编程能力。支持 128K 上下文长度。
   - MoE 架构显著降低推理成本（激活参数少，总参数大）。强大的代码生成与理解能力（DeepSeek-Coder 在 HumanEval 排名靠前）。支持多语言，但中文优化突出。
   - 适用场景:软件开发辅助（代码补全、调试、解释）技术文档生成与问答。企业私有化部署（开源+商用许可友好）。
- Qwen（通义千问）
   - 代表模型：Qwen-Max、Qwen-Plus、Qwen-Turbo、Qwen-VL、Qwen-Audio、Qwen2/Qwen3。
   - 基于 Transformer 架构，部分版本采用 MoE（如 Qwen2-MoE）支持最长 32768 tokens（部分版本支持 128K）。全栈模型家族（文本、多模态、语音、Agent）。中文理解与生成能力极强。
   - 中文企业智能客服、内容生成、数据分析。多模态任务（图文理解、语音转写）。私有化部署与定制化训练（金融、政务等敏感场景）。
- 豆包（Doubao，字节跳动）
   - 基于自研 Transformer 架构。
   - 面向 C 端用户，强调易用性和生活场景。
   - 个人助理（日程管理、知识问答）。学生学习辅导（解题、作文）。轻量级内容创作（短视频脚本、文案）。
- GPT 系列（OpenAI）
   - 基于改进的 Transformer，可能采用 MoE（GPT-4 据传为 MoE）。支持 128K 上下文（GPT-4 Turbo）。
   - Function Calling、Agent 能力成熟。
   - 高端内容创作（广告、剧本、报告）复杂任务自动化（数据分析、代码生成）国际化企业客服与知识管理。
- Kimi（月之暗面）
   - 基于自研大模型，支持200万字（约 1M tokens）上下文,超长上下文处理能力行业领先,擅长 PDF、Word 等文档解析与总结。
   - 中文优化好，支持学术、法律、金融长文本。法律合同分析、学术论文综述,金融研报解读、长篇文档摘要,教育领域（教材/讲义理解）。
- Llama 系列（Meta）
   - 纯 Transformer，Llama 3 有 8B 和 70B 版本，训练数据达 15T tokens。
   - 支持 8K 上下文（部分微调版支持更长）,完全开源（可商用，需申请）。
   - 学术研究、模型微调实验,本地化 AI 应用（如桌面助手、嵌入式设备）,英文为主的低成本企业应用。
- Grok（xAI，埃隆·马斯克旗下）
   - 代表版本：Grok-1、Grok-1.5、Grok-2（2024年发布）。
   - Grok-1 开源（314B 参数，MoE 架构）,实时信息强
   - 社交媒体内容生成与分析,实时新闻摘要与观点提炼,娱乐性对话、个性化推荐。
- 文心一言（ERNIE Bot）—— 百度
   - 基于 ERNIE 4.5 架构，融合知识增强、检索增强（RAG）与大模型生成。支持文本、图像生成（文心一格）、语音合成。上下文长度达 128K tokens。
   - 品牌营销文案、SEO 内容生成,知识问答（尤其百度知识库覆盖领域）,企业智能客服（对接百度云）。
- 讯飞星火（iFlytek Spark）
   - 聚焦语音+教育+医疗垂直领域
   - 智能语音助手（车载、家居）,在线教育平台（AI 家教、自动批改）,医疗问诊辅助（预问诊、报告解读）。
- 智谱清言（ChatGLM）—— 智谱 AI & 清华大学
   - ChatGLM-3/ChatGLM4,强调开源+学术+轻量化部署
   - 基于 GLM（Generalized Autoregressive Model）架构，非标准 Transformer。支持 128K 上下文（GLM-4）开源模型包括 6B、9B、12B 等版本，支持消费级 GPU 微调。
   - 学术研究、教学实验,个人开发者微调私有模型,中文逻辑问答、知识推理。
- 腾讯混元（HunYuan）
   - HunYuan-Large支持多模态,基于 Transformer,支持文本、图像生成、代码、Agent,上下文长度 32K–128K。
   - 社交媒体内容运营（公众号、视频号脚本）,游戏智能 NPC 对话系统,腾讯系广告文案生成。
- 华为盘古大模型（Pangu LLM）
   - 面向政企、工业、科研场景,包括 Pangu NLP、Pangu Vision、Pangu Scientific 等子模型。
   - 基于昇腾 AI 芯片优化，支持千亿参数
   - 政务智能问答、公文生成,工业设备故障诊断,科研辅助（如材料设计、气候建模）
- Claude（Anthropic）
   - 强调AI 安全与对齐,Claude 3.5 Sonnet
   - 基于 Constitutional AI（宪法 AI）训练框架,支持 200K 上下文，多模态（图像理解）。
   - 长文档处理能力极强,输出风格冷静、专业、少“幻觉”
   - 法律合同审查、财报分析,学术论文精读与综述,高安全性企业知识管理。
- Gemini（Google）
   - Google DeepMind 开发，对标 GPT-4,最新Gemini 2.5 Pro
   - 原生多模态架构（非后期拼接),支持 1M tokens 上下文
   - 多模态内容创作（视频脚本+配图+配音),教育（看图解题、实验演示）,国际化企业办公自动化。



### 提示词工程

- 提示词工程是什么
   - 是一门设计与优化输入提示（Prompt），以引导大语言模型生成更准确、相关、高质量输出的学科、艺术和技术。它本质上是人与AI模型之间的“沟通术”
   - 目标：最大限度地激发模型的内在潜力，减少其产生幻觉、答非所问或内容空洞的可能性
- 提示词工程中的方法和技巧
   - 基础核心技巧
      - 明确指令:直接、清晰地告诉模型你要什么。避免模糊不清
      - 提供上下文:给模型足够的背景信息，让它更好地理解你的意图。
      - 指定角色:让模型扮演一个特定角色，可以使其输出的风格和内容更贴近需求。
      - 使用分隔符:使用`"""`， `---`, `<>`, `XML标签`等符号将指令、上下文和需要处理的内容清晰分开，避免混淆。
      - 结构化输出:要求模型以特定格式（如JSON、Markdown、表格、列表）输出，便于后续程序解析或阅读。

| 分隔符类型        | 示例                               | 说明                                                   |
| ----------------- | ---------------------------------- | ------------------------------------------------------ |
| 三重引号          | `"""` 或 `'''`                     | 常用于包裹多行文本，尤其在代码或自然语言中表示“内容块” |
| 三重破折号        | `---`                              | 简洁清晰，适合分隔不同逻辑段落                         |
| 三重等号          | `===`                              | 强调分隔，视觉上更醒目                                 |
| 尖括号            | `<instruction> ... </instruction>` | 类似 XML 标签，结构化强                                |
| 方括号            | `[User]: ...` `[Assistant]: ...`   | 用于角色或模块标识                                     |
| 花括号            | `{context} ...`                    | 有时用于变量或占位符，但需注意与模板语法冲突           |
| 特殊符号组合      | `###`、`***`、`>>>`                | 自定义风格，常用于强调或分段                           |
| 空行 + 注释式标题 | `# 指令` `请总结以下文本...`       | 类似代码注释，适合人类阅读                             |



- 高级方法与策略
   - 零样本提示:不提供任何示例，直接给出指令。依赖于模型已有的知识.“‘踌躇满志’是什么意思？”
   - 少样本提示:在指令中提供一个或多个输入-输出的示例，让模型通过类比来学习任务
   - 思维链:对于复杂推理问题，在提示中要求模型“一步一步地思考”或展示其推理过程。这能显著提升数学、逻辑问题的正确率
   - 自我验证/自我批判:要求模型在给出最终答案后，检查自己的回答是否存在错误或不合理之处
   - 任务分解:将一个复杂任务拆解成多个简单的子任务，通过多个提示或在一个提示中分步骤完成
- 提示词工程包含哪些常见常考点
   - 提示词分析与改进：给出一段质量不佳的提示词，要求你分析问题并重写优化。
      - 常见问题：指令模糊、缺乏上下文、未指定格式、任务过于复杂。
   - 设计特定任务的提示词：
      - 文本摘要：要求对不同长度、不同风格的文本进行总结。
      - 文本分类：设计提示词让模型进行情感分析、主题分类等。
      - 信息抽取：从一段文字中提取关键信息（如姓名、日期、事件）并以结构化形式输出。
      - 代码生成/调试：给出需求写代码，或给出代码让其找错误。
   - 角色扮演场景：设计一个场景，要求让模型扮演特定角色（如老师、律师、客服）进行回答。
   - 处理复杂多步任务：使用任务分解技巧，设计一个包含多个步骤的提示流程。
- 原则与陷阱类
   1. 清晰性原则：为什么清晰明确的指令优于冗长模糊的指令？
   3. 偏见与安全性：如何设计提示词以避免模型生成带有偏见、有害或不安全的内容？
   3. 上下文窗口与令牌限制： 理解模型能处理的文本最大长度，以及如何处理超出限制的长文本（如检索、摘要、分层处理）。
   2. 位置偏差： 模型可能会更关注上下文开头或结尾的信息。如何通过提示设计（如指令位置、关键信息位置）来缓解这种偏差。
   3. 少样本学习的效果与局限： 为什么少样本提示有效？它在什么情况下会失效？（例如示例数量、质量、多样性不足）。
   1. 提示注入： 理解什么是提示注入攻击（用户输入中包含指令，试图覆盖系统预设），以及如何防御（如使用分隔符、输入过滤、多层提示结构）。
   2. 幻觉： 模型会生成看似合理但实际错误的内容。考察如何通过上下文工程（如要求引用来源、提供事实依据、RAG）来减少幻觉。
   3. 不一致性： 同样的提示，模型可能给出不同的答案。如何通过设置随机种子、调整“温度”参数，以及在提示中强调确定性来增加输出的一致性。



### 动态窗口上下文

- 将上下文构建从一个简单的一次性的检索动作，转变为一个智能的、多步骤的、由查询驱动的决策流程
- 静态优化的弊端
   - 朴素检索： 从知识库中检索出Top-K个最相关的文档片段，然后全部塞进上下文
   - 固定长度摘要： 对长文档进行摘要，但摘要可能丢失对当前问题至关重要的细节
- 如何工作
   - 意图识别与查询分析:在检索之前，先理解用户查询的本质
     - 复杂度： 是简单的事实问答（简单），还是需要多步推理、比较或总结（复杂）？
     - 信息范围： 答案可能来自单个文档（聚焦）还是多个分散的文档（分散）？
     - 信息类型： 是需要具体的数字/代码（具体），还是概念性的描述（抽象）？
   - 自适应检索策略
      - 对于简单、聚焦的查询:使用高精度的语义相似性搜索，只召回1-2个最相关的、信息密度高的小片段。
      - 对于复杂、分散的查询采用混合检索。
          - 步骤1： 进行多轮、多角度的检索。例如，先分别检索“Linux安装”和“Windows安装”的相关部分。
          - 步骤2： 如果查询涉及推理，可能会使用 “假设性”检索，即先让LLM生成一个初步的推理链条，然后根据这个链条中的关键步骤，去检索支撑性的证据。
          - 工具使用： 可能会调用摘要工具，先对某个冗长的章节进行摘要，再将摘要和关键细节一起注入。
   - 相关性过滤与重排
      - 使用一个“重排器”模型对检索到的所有片段进行二次评分和排序，只保留相关性得分最高的那几个。这个过程是动态的，因为它依赖于当前查询与每个片段的交互来计算分数。
- 智能内容组装与压缩
  - 指令性压缩： 在提示中加入指令，如“请仅从提供的上下文中寻找答案，忽略任何不相关的部分。”
  - 提取式摘要： 只提取与问题直接相关的句子和短语，而不是整个段落。
  - 抽象式摘要（高级）:使用一个小型、高效的LLM，针对当前查询，对检索到的长片段进行实时摘要，只保留其核心含义，然后将这个摘要（而非原文）放入主LLM的上下文中
- 一个技术实例：Graph RAG 与 Agentic RAG
   - Graph RAG： 将知识库构建成一个知识图谱。当查询进入时，系统不是简单地进行向量检索，而是在图谱上进行“遍历”，动态地找到与查询相关的实体和关系路径，然后只将这些路径上的关键信息组装成上下文。这是一种基于逻辑关系的动态优化。
   - Agentic RAG： 引入一个“代理”来决定如何优化上下文。这个代理会：
     1. 分析问题：“这是一个需要比较的问题。”
     2. 制定计划：“那我需要先检索A的特点，再检索B的特点。”
     3. 执行行动：分别进行两次检索。
     4. 观察结果：“检索到的关于A的信息太多了，我需要先对其进行摘要。”
     5. 最终组装：将摘要后的A信息和原始的B信息组合，形成最终的上下文。



### 大模型选型评估方法与标准

- 大模型选型评估方法与标准
  - 业务需求匹配度
    - 任务类型适配：
      - 理解类任务（投诉分类、实体提取）：优先选 Encoder-only 模型（BERT、ERNIE）或 LLM 的理解能力增强版；
      - 生成类任务（问答、摘要）：优先选 Decoder-only 模型（Llama 3、Qwen）；
      - 多模态任务（证照识别 + 问答）：优先选通义千问 V2、GPT-4o 等多模态 LLM。
    - 性能优先级排序：
      - 核心审批场景：优先保障 “准确率”（目标≥95%），容忍适度延迟；
      - 实时交互场景（智能客服）：优先保障 “推理延迟”（目标≤1s）；
      - 边缘部署场景（社区终端）：优先保障 “模型体积”（目标≤10GB）与低功耗。
  - 技术可行性评估
    - 算力适配：中小算力（单 GPU/4 卡集群）选择 7B/13B 参数量模型（Qwen-7B、Llama 3-8B）；大算力（16 卡以上集群）可选择 70B 参数量模型（Llama 3-70B、文心一言企业版）；
    - 生态成熟度：优先选择社区工具丰富的模型（如 Llama 3 支持 LangChain、vLLM、LoRA 等工具集成），降低政务系统对接与二次开发成本。
  - 合规与安全可控
    - 数据安全：涉及个人信息、企业机密等敏感数据，必须选择支持私有化部署的模型（Qwen、Llama 3），禁止使用纯公有云 API 模型；
    - 隐私性保护:针对政务敏感数据（如市民身份证号、企业税务信息），采用联邦学习（多机构数据 “可用不可见”，联合训练模型）、差分隐私（添加噪声保护个体信息，如统计政务服务满意度时避免识别单个用户反馈）、同态加密（加密状态下数据计算）等技术，符合《个人信息保护法》《数据安全法》要求。
    - 数据流转:基于 “数据分级分类” 理论，对公开、内部、秘密、机密级政务数据采取差异化处理，公开数据可直接用于模型训练，机密级数据需加密存储并限制模型训练环境的访问权限。
    - 国产化适配：政务核心系统需选择通过国产化认证的模型（华为盘古、讯飞星火），适配鲲鹏服务器、昇腾 GPU 等国产化硬件；
    - 备案合规：生成式 AI 模型需完成《生成式人工智能服务管理暂行办法》要求的备案，避免合规风险。
    - 伦理与偏见放空:通过 “多样化训练数据”（覆盖不同区域、人群的政务数据）减少模型偏见（如避免对特定区域的诉求处理产生歧视），建立模型伦理审查机制，禁止模型输出违反政务规范的内容，确保 AI 应用符合公序良俗与行政伦理。
  - 技术生态与易用性:部署方便、社区活跃、工具支持广泛
  - 可扩展性与定制化:支持微调、上下文长度支持



- 模型性能评估指标常见考察点
  - 基础性能指标
    - 准确率： 最直观的指标，指模型输出正确结果的比例。适用于分类、问答等有明确对错的任务。
    - 困惑度： 衡量模型对一组数据预测的不确定性。困惑度越低，说明模型对这段文本越“不困惑”，即建模得越好。常用于语言模型预训练阶段的评估。
    - BLEU / ROUGE：
      - BLEU： 常用于机器翻译，通过比较模型输出和参考译文之间的n-gram重合度来评分。
      - ROUGE： 常用于文本摘要，通过计算召回率等指标来衡量摘要内容覆盖关键信息的程度。
    - F1分数： 精确率和召回率的调和平均数，在需要平衡漏判和误判的场景（如信息抽取、命名实体识别）中非常有用。
  - 效果评估

  | 任务类型             | 核心指标                | 政务目标值                       | 评估工具与方法                                  |
  | -------------------- | ----------------------- | -------------------------------- | ----------------------------------------------- |
  | 文本分类（投诉分类） | 准确率、F1 值           | 准确率≥95%，F1≥94%               | 训练集：测试集 = 8:2，Scikit-learn 计算         |
  | 实体识别（政策实体） | 精确率、召回率、F1 值   | 召回率≥92%                       | 人工标注测试集，SeqEval 库计算                  |
  | 问答生成（政策咨询） | BLEU、ROUGE-L、人工评分 | ROUGE-L≥60%，人工≥4 分（5 分制） | NLTK 计算指标，人工评估准确性 / 完整性 / 合规性 |
  | 摘要生成（会议纪要） | 困惑度、人工评分        | 困惑度≤30，人工≥4 分             | 模型计算困惑度，人工评估信息覆盖率              |

  - 性能评估
    - 推理延迟：单条请求处理时间，文本任务≤500ms，长文本≤2s（Python time 模块、Prometheus 监控）；
    - 吞吐量（QPS）：每秒处理请求数，政务客服场景≥30 QPS（JMeter 模拟 1000 并发压测）；
    - 算力成本：单条推理 GPU 显存占用，边缘部署≤8GB（nvidia-smi 实时监控）。
  - 合规性评估
    - 输出合规率：无敏感词汇、错误政策表述占比，目标 100%（百度 AI 内容审核 API 批量检测）；
    - 可解释性：能提供决策依据的输出占比，目标≥90%（SHAP、LIME 生成解释报告）；
    - 偏见度：不同群体（区域 / 企业类型）输出偏差，目标≤5%（IBM AI Fairness 360 检测）。



- LLM落地关键技术
  - 模型轻量化:(通过 INT8/INT4 量化将 32 位浮点数权重转为低精度整数)
  - 模型裁剪：去除冗余权重参数（权重绝对值＜1e-4）
  - 长文本处理能力优化:支持长上下文模型、上下文摘要生成
  - 推理引擎优化:◦CPU 部署用 OnnxRuntime，GPU 部署用 vLLM（支持 PagedAttention，吞吐量提升 5~10 倍）、TensorRT-LLM（NVIDIA 专用，延迟降低 40%）；支持设定批量推理
  - 缓存策略:热点缓存：用 Redis 缓存高频问答（如 “社保缴费基数”“营业执照材料”），命中率目标≥60%；◦ 上下文缓存：缓存多轮对话的 KV（键值）计算结果，后续对话仅计算新内容，延迟降低 30%-50%。



- 选型实战案例

案例 1：区县级政务智能问答机器人选型

**•** ***\*需求\****：部署于区政务小程序，支持政策咨询、投诉引导，算力有限（单台 16GB GPU 服务器），数据需本地处理。

**•** ***\*选型流程\****：

a. 范围筛选：排除闭源 API 模型，聚焦开源中文 LLM（Qwen-7B、Llama 3-8B）；

b. 测试评估：Qwen-7B 中文问答准确率 96%，INT8 量化后延迟 450ms；Llama 3-8B 准确率 94%，延迟 380ms；

c. 决策落地：选择 Qwen-7B（INT8 量化版），平衡准确率与算力适配性。



案例 2：市级政务政策摘要系统选型

**•** ***\*需求\****：处理百页级政策文件，生成结构化摘要，需高准确性与长上下文支持。

**•** ***\*选型流程\****：

a. 范围筛选：排除小参数量模型，聚焦长上下文模型（Qwen-7B-LongContext、文心一言企业版）；

b. 测试评估：文心一言摘要核心信息覆盖率 92%，支持 128K 上下文；Qwen-7B-LongContext 覆盖率 88%，支持 64K 上下文；

c. 决策落地：选择文心一言企业版（私有化部署），适配长文本处理与政务知识准确性需求。

