# 大数据基础

### Hadoop生态体系核心概念

- HDFS:即Hadoop Distributed File System将大文件自动切分成多个块（Block，默认128MB），并分布存储在一个集群的多个节点上，并提供副本机制以实现高容错性

  - NameNode：主节点，负责管理文件系统的元数据（文件名、目录结构、文件块信息、块所在DataNode等）。单点故障是其经典问题。
  - DataNode：从节点，负责存储实际的数据块，并定期向NameNode汇报其存储的块列表。
  - Secondary NameNode：注意！它不是NameNode的热备。它的主要工作是定期合并NameNode的镜像文件（FsImage）和编辑日志（Edits），以减少NameNode重启时间，并辅助恢复，但不能无缝接管工作。

  ```python
  # 请简述HDFS的写流程和读流程。
  写流程：客户端 -> 请求NameNode -> NameNode返回可写的DataNode列表 -> 客户端将数据块写入管道中的第一个DataNode -> 第一个DN存储后传给第二个 -> 依次传递，形成管道 -> 所有DN确认写入后，客户端确认。
  读流程：客户端 -> 请求NameNode -> NameNode返回文件块所在的DataNode列表 -> 客户端直接从最近的DataNode读取数据。
  # NameNode和Secondary NameNode的区别与联系？Secondary NameNode是热备吗？
  区别：NN是主节点，管理元数据；SNN是辅助节点，定期合并FsImage和Edits，帮助NN减轻负担。
  不是热备。SNN无法在NN宕机时立即接管服务。
  # HDFS如何保证数据的可靠性？
  多副本机制：默认3个副本，分布在不同的机架。
  心跳机制：DataNode定期向NameNode发送心跳，NameNode据此判断DN是否存活。
  数据完整性校验：客户端读取数据时会进行校验和检查。
  机架感知：将副本放在不同的机架上，防止整个机架故障导致数据丢失。
  # Combiner和Partitioner的作用？
  Combiner：是一个本地的“Reduce”操作，在Map端先对输出进行局部聚合，减少网络传输量。注意：Combiner不影响最终的业务逻辑。
  Partitioner：决定Map输出的每个Key-Value对由哪个Reduce Task处理，默认是Hash Partitioner。用于实现数据分发。
  ```
  
- MapReduce:分布式计算框架,分为两个阶段:Map阶段：将输入数据分割成独立的块，由多个Map任务并行处理。Reduce阶段：将Map阶段输出的中间结果，按照Key进行分组和聚合，由多个Reduce任务并行处理

  - **ResourceManager**：主节点，负责整个集群的资源管理和调度。
  - **NodeManager**：从节点，负责单个节点上的资源管理和任务执行。
  - **ApplicationMaster**：每个应用程序（如一个MapReduce作业）都有一个，负责向ResourceManager申请资源，并和NodeManager协同来执行和监控任务。

- YARN:即Yet Another Resource Negotiator,使得Hadoop可以运行除MapReduce之外的其他计算框架（如Spark、Flink）

  ```python
  # 请简述YARN的架构和任务提交流程。
  架构：ResourceManager, NodeManager, ApplicationMaster, Container。
  流程：Client提交应用 -> RM为应用分配一个Container并启动AM -> AM向RM注册并申请资源 -> RM分配资源 -> AM与NM通信，在分配的Container中启动任务 -> 任务执行并向AM汇报状态 -> 应用完成，AM向RM注销。
  # YARN相比传统MapReduce架构的优势？
  解耦：将资源管理和任务调度/监控分离。
  通用性：可以支持多种计算框架（MapReduce, Spark, Flink等），提高了集群资源利用率。
  ```

- Hive:数据仓库工具。它将结构化的数据文件映射为一张数据库表，并提供**HQL**查询功能，HQL底层会被转换为MapReduce、Tez或Spark任务来执行.**元数据存储**（通常存在MySQL/PostgreSQL中）、**分区**、**分桶**。适合做离线批处理

  ```python
  # Hive内部表与外部表的区别？
  内部表：Hive管理数据和元数据。DROP表时，数据文件和元数据都会被删除。
  外部表：Hive只管理元数据。DROP表时，只删除元数据，不删除HDFS上的数据文件。生产环境更常用外部表，避免误删数据。
  # Hive分区和分桶的区别？
  分区：根据某一列的值（如日期dt）将数据分布到不同的子目录中。用于粗粒度过滤数据，避免全表扫描。
  分桶：根据某一列的Hash值将数据分布到固定数量的文件中。用于细粒度数据采样、提升Join效率等。
  # Hive的底层执行引擎有哪些？
  MapReduce（默认，稳定但慢）、Tez（优化了DAG，更快）、Spark（基于内存，最快）。
  ```

- Hbase:分布式、面向列的NoSQL数据库.基于HDFS存储

  ```python
  # 请简述HBase的架构（RowKey设计是核心考点）。
  架构：HMaster（管理）、RegionServer（服务）、Region（数据分片）、ZooKeeper（协调）。
  RowKey设计原则：唯一性、长度原则、散列原则（避免热点问题）、满足业务查询需求。
  # HBase的存储结构（LSM树）了解吗？
  LSM树通过将随机写转换为顺序写（先写WAL和MemStore），再在后台周期性地将MemStore刷新到磁盘形成HFile，极大地提升了写性能。
  ```

- ZooKeeper:分布式协调服务,提供一个类似于文件系统的树形结构，实现如**统一命名服务**、**状态同步服务**、**集群管理**、**分布式锁**等

- Spark:通用、快速的分布式计算引擎。可以看作是MapReduce的增强版,基于内存计算

  ```python
  # Spark为什么比MapReduce快？
  内存计算：中间结果尽量放在内存中，减少磁盘I/O。
  DAG引擎：Spark的DAG调度器能进行更高级的优化，而MapReduce的MR模型固定，中间结果必须落盘。
  线程模型：Spark Task在Executor中是线程，轻量；MapReduce Task是进程，启动开销大。
  ```

- Sqoop:用于在Hadoop（HDFS/Hive/HBase）和传统关系型数据库（MySQL, Oracle等）之间进行数据传递的工具

- Flume:一个高可用的、高可靠的、分布式的海量**日志采集、聚合和传输**系统。常用于将日志数据从各种Web服务器收集到HDFS中

- Kafka:布式、高吞吐量的**消息队列/事件流平台**。常用于构建实时数据管道和流式应用

- Oozie & Azkaban:工作流调度引擎。用于管理和调度复杂的Hadoop作业依赖关系（例如，先运行Hive SQL，再运行Sqoop导出）



### Spark生态体系核心概念

**RDD（弹性分布式数据集）**

- **核心概念**：不可变、可分区的分布式对象集合。是Spark最基础的数据抽象。
- **特性（常考四大特性）**：
  - **分区列表（A list of partitions）**：数据逻辑分片的基本单位。
  - **依赖关系（A list of dependencies）**：RDD之间的血缘关系（Lineage），用于容错。
  - **计算函数（A function for computing the split）**：对每个分区的计算逻辑。
  - **分区器（Optionally, a Partitioner）**：决定数据如何分片（如HashPartitioner, RangePartitioner）。
  - *（可选）优先位置列表（Optionally, a list of preferred locations）*：用于数据本地性。
- **容错机制 - 血缘关系（Lineage）**
  - **原理**：通过记录RDD的转换历史（血缘图），当某个分区数据丢失时，可以根据血缘重新计算该分区，而无需回溯整个流程。

**DAG（有向无环图）与执行计划**

- **DAGScheduler**：将Job的RDD血缘关系图转换成DAG，并划分Stage。
- **Stage（阶段）**：
  - **宽依赖（Shuffle Dependency）**：一个父RDD的分区数据被多个子RDD分区使用（如`groupByKey`, `reduceByKey`）。**宽依赖是Stage划分的依据**。
  - **窄依赖（Narrow Dependency）**：一个父RDD的分区数据最多被一个子RDD分区使用（如`map`, `filter`）。
  - **结论**：Stage内部是一连串的窄依赖，Stage之间是宽依赖。

**任务调度**

- **Job**：由一个Action触发产生的计算作业。
- **Stage**：如上所述，一个Job被划分为多个Stage。
- **Task**：一个Stage内，每个分区对应一个任务。Task是最终在Executor上执行的基本单位。
- **流程**：`Action` -> `Job` -> `DAG` -> `Stages` -> `Tasks` -> `Scheduler` -> `Cluster Manager` -> `Executors`

**DataFrame & Dataset**

- **DataFrame**：等同于关系型数据库中的表
- **Dataset**：强类型API，享受Spark SQL优化引擎
- **与RDD的区别**：
  - **优化**：Spark SQL有Catalyst优化器和Tungsten执行引擎，执行效率通常高于直接编写RDD代码。
  - **API**：提供更高级、更易用的DSL（领域特定语言）和SQL接口。
  - **数据源**：对各类数据源（Parquet, JSON, JDBC等）的支持更完善。

**Catalyst 优化器**

- **核心**：Spark SQL的核心，负责对SQL查询和DataFrame操作进行优化。
- **优化流程**：
  1. **逻辑计划（Logical Plan）**：分析阶段，解决表名、列名引用。
  2. **逻辑优化（Logical Optimization）**：应用规则优化，如谓词下推、列剪裁、常量折叠等。
  3. **物理计划（Physical Planning）**：生成一个或多个可执行的物理计划。
  4. **代码生成（Code Generation）**：使用Tungsten生成高效的Java字节码。

**Tungsten 执行引擎**

- **目标**：突破JVM对象管理和GC开销的瓶颈，接近硬件性能极限。
- **特性**：
  - **堆外内存管理**：自行管理内存，避免GC。
  - **缓存敏感计算**：优化数据结构和算法，充分利用CPU缓存。
  - **代码生成（Whole-Stage Code Generation）**：将整个Stage编译成一个函数，减少虚函数调用和中间对象创建。

**核心概念 - DStream（离散化流）**

- **本质**：将连续的数据流切分成一系列小的、不连续的批处理RDD，然后使用Spark引擎进行处理。即“微批处理”模型。
- **工作原理**：以时间片（如1秒）为单位，将实时输入数据流切分成批（Batch），每个Batch数据对应一个RDD。

**结构化流（Structured Streaming）**

- **核心理念**：基于Spark SQL引擎，将无限增长的动态表（Unbounded Table）作为流数据的抽象。你可以像查询静态表一样查询流数据。
- **输出模式**：`Append`（仅追加）、`Update`（更新更改的行）、`Complete`（更新整个结果表）。
- **与DStream对比**：
  - **API统一**：使用DataFrame/Dataset API，与批处理代码高度一致。
  - **端到端Exactly-Once保证**：在支持的回写端（Sink）上，能提供端到端的精确一次语义。
  - **更优的性能**：得益于Catalyst和Tungsten。



### 数据仓库与数据湖概念

- 数据仓库:存储的是为特定分析目的而加工过的、高质量的数据。典型流程ETL（Extract, Transform, Load）
- 数据湖:存储的是全量的、原始的数据，为未来的各种可能性做准备
- 数据湖仓：在数据湖的低成本存储之上，构建了数据仓库的管理和性能层。它既具备了数据湖的灵活性（存储原始数据），又提供了数据仓库的数据管理和优化能力（支持ACID事务、Schema管理等），使得直接在数据湖上进行高性能的SQL分析成为可能。



### 数据建模

- 传统数仓强调**集成、一致、高性能**；大数据平台更强调**原始数据存储、敏捷探索、支持多样化的计算范式**
- 数据分层理论:ODS（操作数据层）贴源存储，DWD（数据明细层）清洗、标准化，DWS（数据汇总层）轻度/重度聚合，ADS（数据应用层）面向特定应用。目的是解耦、降低重复计算、统一数据口径、保证数据质量
- 设计架构
  - **Lambda**： 批层（全量数据，高延迟高准确）+ 速度层（增量数据，低延迟近似结果）+ 服务层（合并视图）。考点在于其**优缺点（复杂、维护两套逻辑）**。
  - **Kappa**： 将所有数据视为流，通过一个流处理引擎处理，并通过**消息队列（如Kafka）的数据重放能力**来替代批层。考点在于其**简化架构**的前提和**适用场景**。
- 星型模型:由一个**事实表（Fact Table）和多个维度表（Dimension Tables）**组成。维度表直接连接到事实表，不进行规范化（即可能存在数据冗余）。优点:强调查询性能、BI 工具兼容性好（如 Tableau、Power BI 偏好星型）、维度变化少.(存储换性能),更常用
- 雪花模型:是星型模型的规范化扩展。维度表被进一步拆分为多个关联的子维度表（即维度表也存在层级关系）优点:维度属性非常多、存在明显层级（如国家→省→市）、存储成本敏感、需要减少数据冗余.(性能换存储)
- Data Vault模型:强调**可追溯性、敏捷性、易于扩展**，能够很好地适应源系统的变化，**为构建“可信赖、可演进、可审计”的数据底座而生**,核心组件 Hub（业务键）、Link（关系）、Satellite（描述性属性）
- 宽表模型:通过大量的JOIN操作，将多个维度的属性冗余到一张事实表中，形成一张大宽表.**查询性能极佳**（减少JOIN），但**数据冗余大、维护复杂、灵活性差**
- 数据存储结构
  - 行式存储:按记录（行）为单位存储数据，每条记录的所有字段连续存放.优点:写入高效、记录完整数据、便于调试.缺点:io浪费严重、压缩率低
  - 列式存储:按列存储，同一列的所有值连续存放.优点:高压缩比、适合列裁剪、谓词下推(过滤条件（如 `age > 30`）可在存储层过滤数据块，减少数据传输)、向量化读取(适合现代 CPU 的 SIMD 指令).缺点:写入开销大、不适合查询完整数据



### 数据治理

1. **数据治理的定义与目标**
   - 数据治理不是数据管理，核心是建立一个框架，确保数据资产得到正式的管理
   - 包括：确保数据质量、保障数据安全与合规、促进数据共享与利用、降低数据风险、提升数据价值
2. **数据治理的核心驱动力**
   - 为什么企业需要数据治理？
   - 法规合规（如GDPR、数据安全法）、数字化转型、数据驱动决策、数据孤岛整合、降低运营成本
3. **数据治理框架的组成要素**
   - 一个完整的数据治理体系包含哪些关键组成部分？
   - 组织架构（如数据治理委员会、数据所有者）、政策流程（如数据标准、数据分类）、技术工具（如元数据管理、数据血缘）、规章制度（如数据安全策略）
4. **元数据管理**
   - 元数据的类型（业务、技术、操作元数据）及其价值。如何通过元数据进行数据发现、数据血缘分析。
   - 元数据是“关于数据的数据”。数据血缘用于影响分析（上游变更对下游的影响）、根因分析（数据问题溯源）、合规审计
5. **数据质量管理**
   - 数据质量的维度（准确性、完整性、一致性、时效性、唯一性、有效性）。数据质量监控和提升的流程。
   - 定义质量维度 -> 定义质量规则 -> 质量探查与评估 -> 质量问题监控与告警 -> 整改与报告
6. **数据安全与隐私**
   - 数据分类分级、数据脱敏（静态/动态）、数据加密、访问控制、数据防泄漏
   - 根据敏感度（公开、内部、秘密、绝密）和类型（个人信息、商业机密）进行分类。静态脱敏用于开发测试，动态脱敏用于生产环境实时查询。
7. **主数据管理**
   - 主数据的概念（客户、产品、员工等核心实体）。如何解决主数据不一致的问题，实现“单一视图”。
   - MDM是DG的一个关键应用领域。DG为MDM提供政策和治理框架，MDM是实现高质量、一致主数据的具体实践。
8. **数据生命周期管理**
   - 数据从创建、存储、归档到销毁的各个阶段
   - 创建 -> 存储 -> 使用 -> 共享 -> 归档 -> 销毁。热数据高速存储，冷数据低成本对象存储，根据法规要求设定保留期限。
9. **数据治理的组织架构**
   - 数据所有者、数据管家、数据治理委员会的角色和职责。
   - 数据所有者是业务负责人，对数据资产负有最终责任；数据管家是执行者，负责数据质量的日常维护和规则执行。
10. **数据治理的技术工具栈**
    - 数据目录（核心）、数据质量工具、数据建模与设计工具、数据安全与隐私工具、主数据管理平台
11. **数据治理与数据中台的关系**
    - 没有完善的数据治理，数据中台就会变成一个混乱的“数据沼泽”
12. **数据治理的实施策略**
    - “自上而下” vs “自下而上”策略的优缺点。为什么通常推荐“试点先行”的策略？
    - 获得高层支持、选定试点业务领域、建立可衡量的指标、持续沟通与培训
13. **数据治理面临的常见挑战**
    - 文化阻力（部门墙）、难以衡量ROI、缺乏高层支持、技术债务和历史数据问题复杂、法规多变



### 数据脱敏技术

**数据脱敏的定义与目标**

- 脱敏的核心是在保护敏感信息的同时，保留数据的业务价值
- 与加密区别： 加密数据可逆（有密钥即可解密），主要用于数据传输和存储安全；脱敏通常**不可逆**，用于数据使用安全。脱敏后的数据保持格式真实，如手机号`138****1234`。
- 与匿名化区别： 匿名化要求无法通过任何手段识别出个人，标准更严格；脱敏有时可能通过关联其他数据被还原（伪脱敏）。

**静态脱敏 vs. 动态脱敏**

- 静态脱敏:对数据副本进行脱敏处理，然后将处理后的数据交付给使用方
- 动态脱敏:在用户访问数据的瞬间，根据预设策略对返回的结果进行脱敏“实时拦截”

**常见脱敏算法与技术**

- 替换： 用伪造的、但格式一致的数据替换真实数据。如用随机生成的姓名替换真实姓名
- 置乱/洗牌： 在同一列的数据内部随机打乱顺序。如将员工工资列随机打乱
- 泛化： 降低数据精度。如将具体年龄“28”变为年龄段“20-30”；将邮政编码“100101”变为“100***”
- 加密/哈希： 使用单向哈希函数（如MD5, SHA-256）处理数据。通常用于标识符（如用户ID），便于数据关联分析但无法反推真实值
- 掩码： 保留部分数据，隐藏其他部分。如手机号`13800138000` -> `138****8000`，身份证号`11010119900307****`
- 空值化/删除： 直接用NULL或特定符号替换（最安全，但可能破坏数据完整性）
- 合成数据： 利用算法生成完全虚构但符合真实数据统计规律的数据集。（安全性最高，但技术复杂）

**可逆脱敏 vs. 不可逆脱敏**

- 不可逆脱敏： 绝大多数场景，如开发、测试、外包分析。安全系数高。
- 可逆脱敏： 少数特定场景，如运维调试需要临时查看真实数据

**脱敏策略的设计**

- 数据分类分级： 首先识别敏感数据（PII、SPI），如身份证、手机号、银行卡号、余额。
- 角色权限： 不同角色看到不同密级的数据。如：生产客服： 动态掩码（看到部分手机号）。数据分析师： 静态脱敏后的测试库（看到泛化后的年龄段和合成地址）。高管： 可查看统计信息，但看不到个体明细。

**数据脱敏的挑战**

- 保持数据关联性与一致性： 脱敏后，主外键关系、跨表的数据关联必须保持一致。例如，同一个客户ID在所有表中必须被脱敏成同一个假ID。
- 保持数据的业务逻辑与统计特性： 如薪水脱敏后，其分布应符合公司实际情况；城市和邮编应对应。
- 复杂数据类型处理： 对非结构化数据（JSON, XML, 日志文件、PDF）中的敏感信息进行脱敏。
- 性能影响： 尤其是动态脱敏，在高并发查询下不能成为系统瓶颈。
- 管理和运维成本： 脱敏规则的维护、脱敏任务的调度、脱敏后数据的版本管理。

**数据血缘与脱敏的关系**

-  数据血缘可以精准定位敏感数据的来源和流向。当发现某个下游数据集中含有敏感信息时，可以通过血缘追溯至上源，从源头实施脱敏，确保“一处脱敏，处处安全”，避免遗漏。



# 云计算与基础设施

*   虚拟化技术
    *   虚拟化是一种资源管理技术，它通过软件（称为虚拟化管理器或Hypervisor）将物理硬件资源（如CPU、内存、存储、网络）进行抽象、转换和分割，形成一个或多个彼此隔离的虚拟环境（虚拟机）。每个虚拟机都像一台独立的计算机，可以运行自己的操作系统和应用程序
    *   Hypervisor（虚拟化管理器）的类型
        - Type-1（裸机虚拟化管理器）:直接安装在物理服务器硬件上，无需底层操作系统。性能更高、更安全、更稳定。管理相对复杂。 VMware ESXi, Microsoft Hyper-V, Citrix XenServer, KVM
        - Type-2（宿主机虚拟化管理器）：作为一个应用程序安装在现有的操作系统（如Windows, Linux, macOS）之上。易于安装和使用，适合开发和测试。性能有损耗，因为需要经过宿主操作系统Oracle VirtualBox, VMware Workstation, Parallels Desktop
    *   CPU虚拟化
        - 全虚拟化： 通过二进制翻译来截获并模拟虚拟机发出的特权指令，无需修改客户机操作系统。兼容性好，但性能有损耗
        - 半虚拟化： 需要修改客户机操作系统内核，让其知道自己运行在虚拟化环境中，通过一种称为“超级调用”的API与Hypervisor通信。性能优于全虚拟化，但需要开源操作系统配合
        - 硬件辅助虚拟化： 借助CPU硬件特性（Intel的 VT-x 和 AMD的 AMD-V）来直接执行虚拟机的敏感指令，无需二进制翻译或修改操作系统。这是目前主流的、性能最好的方式
    *   内存虚拟化
        - 每个虚拟机都认为自己拥有一段从0开始的连续物理内存空间。Hypervisor维护一个“物理机地址”到“虚拟机物理地址”的映射表。通过影子页表或硬件辅助的扩展页表来高效地完成地址转换。EPT/NPT是当前的主流技术。
    *   I/O虚拟化
        - 全模拟： 完全模拟一个常见的硬件设备（如e1000网卡），兼容性最好，但性能最差
        - 半虚拟化： 在虚拟机和Hypervisor之间使用优化的、虚拟化感知的驱动（如**Virtio**），性能远优于全模拟。Virtio是KVM等开源方案中的事实标准。
        - 设备直通： 将物理I/O设备（如SR-IOV网卡）直接分配给某个虚拟机，虚拟机可以几乎无损耗地直接访问硬件。性能最佳，但设备无法被其他虚拟机共享。
    *   网络虚拟化
        - 虚拟交换机： Hypervisor内部创建一个软件交换机，虚拟机通过虚拟网卡连接到vSwitch上，实现内部通信和外部网络连接。
        - VLAN： 用于在物理网络基础上进行逻辑隔离。
        - Overlay网络技术： 如 VXLAN，通过在物理IP网络之上构建虚拟的、大二层的网络，解决VLAN数量限制和跨物理数据中心的迁移问题，是现代SDN和云网络的核心
    *   缺点与挑战
        - 性能开销： 尽管硬件辅助虚拟化大大降低了开销，但理论上仍存在少量性能损耗。
        - 复杂性增加： 虚拟化层增加了系统的复杂性，对管理员的技能要求更高。
        - 安全挑战： 如果Hypervisor被攻破，所有其上的虚拟机都可能被控制。 攻击者从虚拟机内部突破隔离，获取Hypervisor的控制权。
        - 资源争用： 多个虚拟机竞争同一物理资源（如CPU缓存、内存带宽），可能导致性能不稳定。
*   Docker
    *   与虚拟机的区别:启动速度、性能开销、资源利用率、隔离性。 Docker 使用的是操作系统级别的虚拟化。
    *   Docker 架构（Client-Server）
        - Docker 守护进程（Docker Daemon）：核心引擎，管理容器、镜像、网络、存储卷。
        - Docker 客户端（Docker Client）：用户通过 CLI 与守护进程交互。
        - Docker 注册中心（Docker Registry）：如 Docker Hub，用于存储和分发镜像
    *   镜像（Image）：只读模板，包含创建容器所需的文件和元数据。理解分层存储（Union File System）和写时复制（Copy-on-Write）机制。
    - 容器（Container）：镜像的运行实例。容器 = 镜像 + 可写层。
    *   仓库（Repository）：集中存放镜像的地方。
    *   镜像构建（Dockerfile）:`FROM`：指定基础镜像`RUN`：执行命令并创建新的镜像层`COPY` vs `ADD`：复制文件，`ADD` 有额外功能（解压、URL），但通常推荐 `COPY``WORKDIR`：设置工作目录。`EXPOSE`：声明运行时容器提供的端口`ENV`：设置环境变量`CMD` 提供默认的执行命令，可被 `docker run` 后的参数覆盖`ENTRYPOINT` 指定容器启动时始终运行的命令。如使用 `.dockerignore` 文件、合并 `RUN` 指令以减少镜像层数、使用特定标签而非 `latest`
    *   镜像操作命令`docker build -t <name> .`：构建镜像`docker images` / `docker image ls`：列出镜像`docker pull/push`：拉取/推送镜像到仓库`docker rmi`：删除镜像`docker tag`：给镜像打标签
    *   镜像分层与缓存机制:Dockerfile 的每一行指令都会创建一个新的层。构建镜像时，Docker 如何利用缓存来加速构建过程。改变某一层之后的所有层缓存都会失效。
    *   容器生命周期管理命令:`docker run`：最复杂的命令常用参数`-d`：后台运行（ detached mode）`-it`：交互式运行（分配伪终端）`--name`：指定容器名称`--rm`：退出后自动删除容器`-p`：端口映射（`-p host_port:container_port`）`-v`：存储卷映射`-e`：设置环境变量`docker start/stop/restart`：启动/停止/重启容器。`docker ps -a`：查看所有容器（包括已停止的）`docker rm`：删除容器`docker logs`：查看容器日志`docker exec -it <container> <command>`：在运行中的容器内执行命令。
    *   容器状态: `created`, `running`, `paused`, `restarting`, `exited`, `dead` 
    *   存储卷（Volumes）:数据持久化和共享的最佳方式,由 Docker 管理，存储在宿主机的特定目录（如 `/var/lib/docker/volumes/`）创建命令`docker volume create/ls/inspect/rm`在 `docker run` 中使用 `-v` 或 `--mount` 挂载卷
    *   绑定挂载（Bind Mounts）:将宿主机的任意目录或文件挂载到容器中,与 Volume 的区别：Volume 由 Docker 管理，Bind Mount 依赖于主机目录结构。
    *   临时文件系统（tmpfs）:将数据存储在宿主机的内存中，容器停止后数据消失。
    *   Docker 网络驱动（Network Drivers）
        - bridge：默认,容器通过虚拟网桥连接到宿主机，并分配私有 IP。通过端口映射与外部通信（`-p` 参数）,相当于与宿主机同网络的另一台机器
        - host：容器直接使用宿主机的网络命名空间，没有网络隔离，性能最好。
        - none：禁用所有网络。
        - overlay：用于 Docker Swarm集群，使不同主机上的容器可以通信
        - 命令：`docker network create/ls/inspect/connect/rm`。
    *   容器间通信:在同一 bridge 网络下的容器，可以直接通过容器名进行通信（Docker 内嵌的 DNS 服务）通过 `--link`（已废弃，不推荐）和自定义网络进行通信
    *   故障排查
        *   资源限制:使用 `-m` 或 `--memory` 限制容器内存，使用 `--cpus` 限制 CPU 使用
        *   日志查看与分析:`docker logs`， `docker logs -f`（跟随日志）
        *   容器内进程检查`docker top <container>`：查看容器内运行的进程
        *   镜像优化:如何构建一个体积小、安全性高的镜像（使用多阶段构建 `multi-stage builds`、选择小的基础镜像如 Alpine）
*   Kubernetes
    *   Pod:最小的、可部署和管理的计算单元。一个Pod包含一个或多个紧密相关的容器，这些容器共享网络命名空间、IP地址、存储卷等资源，总是被共同调度和运行在同一个工作节点上。生命周期主要包括：`Pending`（创建中）、`Running`（运行中）、`Succeeded`（成功结束）、`Failed`（失败）等阶段。
    *   Service:定义一组Pod的访问策略，提供稳定的网络端点，是实现服务发现和负载均衡的核心组件`ClusterIP`：默认类型，为Service在集群内部提供一个虚拟IP，只能在集群内部访问`NodePort`：在`ClusterIP`基础上，在每个Node上打开一个静态端口，外部流量可以通过`<NodeIP>:<NodePort>`访问服务`LoadBalancer`：在`NodePort`基础上，使用云服务商的负载均衡器，将外部流量自动引导到后端Pod
    *   Ingress:不是一种Service类型，它是管理外部访问集群服务的API对象，主要提供HTTP/HTTPS路由可以基于主机名和路径规则将流量路由到不同的后端Service，一个Ingress可以暴露多个服务，通常需要配合`Ingress Controller`（如Nginx, Traefik）使用
    *   Deployment vs StatefulSet
        - Deployment：适合管理无状态应用。它确保指定数量的Pod副本持续运行，并支持无缝的滚动更新和回滚。Pod副本是相互替代的，没有独立的身份标识。
        - StatefulSet：适合管理有状态应用（如数据库、有状态中间件）。它为每个Pod提供唯一且稳定的网络标识符（如 `web-0`, `web-1`）和持久化存储。Pod的部署、扩缩容和终止是**有序**进行的（顺序创建，逆序删除）。
    *   ConfigMap & Secret
        - ConfigMap：用于将非敏感的配置数据（如配置文件、环境变量、命令行参数）与容器镜像解耦。数据可以通过环境变量或作为文件挂载到Pod中的卷来使用。
        - Secret：用于存储和管理敏感信息，如密码、OAuth令牌、SSH密钥。用法与ConfigMap类似，但会进行Base64编码。建议在etcd中加密存储。
    *   持久化存储
        - PV：是集群中的一块网络存储资源，由管理员预先配置，或使用StorageClass动态供应。
        - PVC：是用户对存储的请求，类似于Pod消耗Node资源，PVC消耗PV资源。Pod通过在其卷声明中引用PVC来使用PV。
        - StorageClass：描述了存储的“类别”，允许管理员定义不同类型的存储。它可以实现动态卷供应，即根据PVC的请求自动创建对应的PV，无需管理员手动干预。
    *   RBAC:是基于角色的访问控制机制。它通过定义以下资源来控制用户、组或服务账户对集群API资源的权限：Role / ClusterRole：定义一组权限规则（例如，可以对哪些资源执行哪些操作）。Role是命名空间级别的，ClusterRole是集群级别的。RoleBinding / ClusterRoleBinding：将Role或ClusterRole中定义的权限绑定给特定的用户、组或服务账户。RoleBinding在特定命名空间内生效，ClusterRoleBinding在集群范围内生效。
    *   Pod启动失败:1、使用 `kubectl describe pod <pod-name>` 查看Pod的详细事件，这通常会直接指出问题所在（例如，镜像拉取失败、节点资源不足）2、使用 `kubectl logs <pod-name>` 查看容器日志，了解应用本身的启动错误。3、检查资源配额是否足够（CPU、内存）4、验证镜像名称、标签是否正确，以及镜像仓库是否可访问。
    *   节点状态异常:登录到该节点，检查 `kubelet` 服务是否正常运行（例如 `systemctl status kubelet`）检查容器运行时（如Docker或containerd）是否正常,检查网络插件（如Calico、Flannel）的Pod是否正常运行，网络配置是否有问题。
    *   探针:存活探针Liveness Probe：用于判断容器是否存活。如果探测失败，kubelet会重启容器。适用于检测应用死锁等无法自愈的问题。就绪探针Readiness Probe：用于判断容器是否已准备好接收请求。如果探测失败，会将该Pod从关联的Service的负载均衡器中移除，直到探测成功。适用于应用启动时需要加载大量数据或依赖外部服务的场景。
    *   滚动更新与回滚:Deployment控制器支持滚动更新策略。当更新Pod模板时，它会逐步用新版本的Pod替换旧版本的Pod，确保在更新过程中始终有可用的Pod来处理请求，服务不中断。如果更新后出现问题，可以使用 `kubectl rollout undo deployment/<deployment-name>` 命令快速回滚到上一个版本。
    *   HPA:根据观察到的CPU平均使用率**、**内存平均使用率或自定义指标，自动调整Deployment、ReplicaSet或StatefulSet等控制器下的Pod副本数量，以应对流量波动，实现应用的自动扩缩容。
*   微服务架构
    *   微服务是一种将单个应用程序作为一套小型服务集合来开发的架构风格，每个服务运行在独立的进程中，通常对应一个独立的业务能力，并采用轻量级通信机制（如HTTP/REST、gRPC）进行交互。其根本区别在于服务边界的划分：单体架构是所有功能模块内聚在一个应用中，而微服务是按业务领域进行垂直拆分，每个服务都是自治的。
    *   优点：技术异构性、弹性与容错、独立部署与扩缩容、高可扩展性
    *   缺点/挑战：分布式系统复杂性、运维 overhead、数据一致性、接口设计与版本管理
    *   如何划分微服务（领域驱动设计）:最核心的指导方法是领域驱动设计（DDD）。通过识别限界上下文来划分服务边界。
    *   服务发现
        - 客户端发现：客户端从服务注册中心查询所有可用实例列表，并自己决定调用哪一个。例如，Netflix Eureka + Ribbon。
        - 服务端发现：客户端通过一个负载均衡器（如Kubernetes的Service）发起请求，由负载均衡器去查询注册中心并转发请求。例如，Kubernetes Service, Consul。
    *   分布式事务:传统的两阶段提交（2PC）在微服务中因性能和不支持NoSQL而较少使用。现代微服务更倾向于使用最终一致性和以下模式：Saga 模式：将一个分布式事务拆分为一系列本地事务，每个本地事务都会发布一个事件来触发下一个本地事务。如果某个步骤失败，则执行一系列补偿事务来回滚之前的操作。事件驱动架构：服务之间通过发布/订阅领域事件来进行异步通信，松耦合且易于实现最终一致性。
    *   容错与熔断:熔断器模式：当对某个服务的失败调用达到一定阈值时，熔断器会打开，后续请求会立即失败。经过一段时间后，会进入半开状态尝试放行少量请求，根据结果决定是关闭还是再次打开熔断器。例如，Netflix Hystrix, Resilience4j。降级：当服务不可用时，提供默认的响应或缓存数据，保证核心流程可用。限流：控制单位时间内能够处理的请求数量，保护服务不被突发流量击垮。超时与重试：为服务调用设置合理的超时时间，并配合退避策略进行重试。