1. **自我介绍准备：**

   ```python
   尊敬的各位考官，您好：
   
   我叫马浩，拥有6年Java开发经验和2年Python开发经验，具备扎实的全栈开发能力，能够独立完成后端、前端及AI相关项目的开发与落地。最近几年我持续关注并深入实践人工智能技术，尤其在大模型应用、Agent编排和RAG等领域积累了一些实战经验。
   
   在工作中，我参与了基于LangGraph的工作流智能体（Agent）项目开发，负责设计和实现多步骤任务的自动化调度与决策逻辑；同时也深度参与了RAG知识库系统的构建，从数据清洗、向量索引的全流程均有实操经验。此外，还在业余时间开发了开源Python大模型项目，亲自动手进行LLM的调用、集成和优化。这让我对主流大模型的技术特点和应用场景有了更直观、更深刻的认识.
   
   我能够独立完成从后端（Java/Python）到前端的全流程开发。精通RPA自动化技术，能够高效完成重复性高、规则明确的政务或数据类任务自动化.同时，我始终保持对AI前沿技术的敏感度，具备快速学习和工程转化能力，善于将新技术与具体业务需求结合，推动AI能力在政务服务、数据分析等场景中的实际落地。
   
   我非常渴望能在一个像大数据中心这样的平台上实现自己的价值。我知道这个岗位不仅仅是编写代码，更是推动技术赋能业务。我具备良好的沟通能力和团队合作精神，期待能有机会贡献自己的一份力量。
   
   谢谢
   ```

   

2. **项目深挖**

   *   **您的开源Python大模型项目：**
       *   项目目标是什么？前几年短视频很火,我也在休息时间迷恋上了段视频,比如一些影视剧的剪辑视频,小动物、风景类的视频.这个过程中我发现这类视频需要认为介入的不多,只需要选择好配音、字母、背景音就可以快速制作,并且这类视频很容易跨国传播.因此我想能不能利用LLM+RPA实现一套自动化视频剪辑+自动化视频传递的项目.
       *   整体技术方案？easyrpa项目,整个项目后端由python构建,前端使用VUE实现.项目架构上采用平台项目+agent项目的方式.平台负责流程通道的配置、调度、python脚本的自定义编写,agent负责具体流程任务的执行,并且agent通过自动注册的方式注册到平台中.当需要执行流程任务时平台将流程任务参数、流程脚本调度给agent,每一个agent都是一个虚拟机,可以通过执行通道脚本打开浏览器进行视频剪辑、上传等操作.实现全流程无人管控
       *   哪些地方用到了LLM?aivideotools项目负责视频的自动化剪辑,也是深度使用llm的地方.整个自动化剪辑流程大致如下:上传原始视频素材,对原始素材进行元数据拆分,拆分为视频、语音,然后对语音进行识别分析出字幕(开源的whisper-v3),对视频进行ocr识别获取原始字幕位置信息(百度的paddleOCR)并进行打码,然后需要对字幕进行llm重新洗稿,将全新的字幕、视频、背景音进行组合生成新视频
       *   遇到过什么技术挑战？
           *   性能问题:整个视频剪辑项目涉及到非常多的技术点,例如语音识别、ocr视频、llm调用等,例如ocr识别需要对每一帧都进行识别,由于python中GIL的限制多线程效果不理想,需要采用多进程并且需要调优ocr识别参数.还需要对桢数据由深刻的理解,如何利用numpy等对桢进行处理
           *   模型幻觉问题:由于字幕内容是动态的,因此需要对提示词作精细化的控制,例如限定角色、指定任务、限定输出格式.这种方式一定程度解决了幻觉的影响,但是不能根治,后续打算结合workflow进行“思考+行动”分阶段处理.
           *   容器化虚拟化:每一个agent都是一台虚拟机,宿主机是linux系统,利用系统自带的KVM进行虚拟化,保证虚拟机效率达到真实系统水平.中间涉及到网络通信、磁盘管理、agent项目部署等.主项目通过docker部署在宿主机.
       *   项目有什么成果？整个项目已经run起来了,证明技术方向是可行的
       *   其它难点与解决方案?目前主要问题集中在如何实现自动化的影视剧剪辑,这涉及到如何识别剪辑点?如何识别画面内容?如何对不同的画面内容构造出复合视频剧情的解说.目前尝试了多模态模型,只能停留在对单个图片画面的解读上,对完整剧情的理解尚不足.如何解决?大体思路根据语音识别+多模态识别共同分析出视频的剧情,再根据举行分析出需要剪辑的点.
   *   **基于LangGraph的Agent项目：**
       *   **业务场景是什么？**履约系统本质上是推进业务完成完整业务流程的系统,每一个业务节点都包括自定义的事项(可以理解为代办),通过agent来自动分析出需要完成哪些代办?以及每个代办需要做什么动作?
       *   **Workflow是如何设计的？**自己基于langgraph开发了一套workflow引擎,主要是模仿市面上常见的流程引擎,包括开始、结束、服务调用、代码节点、发送邮件、发送钉钉、交互节点等.通过节点的组装来完成一个业务流程.
       *   **如何保证Agent执行的可控性和稳定性？**流程引擎支持代码节点以及llm节点,针对llm的稳定性我们在内部通过提示词规定了结构化输出格式,重试机制等.整个流程的上下文,以及每一个节点的出入参数都进行记录.
       *   您在这个项目中最大的贡献和技术收获是什么？参与部分节点的构建,例如代码执行节点,需要基于沙河模型保证安全型.掌握了整个workflow的建设原理和建设过程.理解了模型并非是万能的,目前模型更适合做语义分析、文本生成、意图识别类的事项.
       *   状态管理策略?利用langgraph的state流转机制构建了全局上下文对象,这个对象包含流程输入输出、每一个节点的输入输出数据,保证了完整的流程上下文记录
       *   性能优化点?后续项目优化点还是要结合实际的请求量来看,目前使用fastapi+uvicon+gunicorn实现了异步请求和多进程管理.但是如果请求量太大,后续要考虑更换底层的解释器,使用cpython等,避免全局解释器锁.
   *   **RAG知识库项目：**
       *   知识库的**数据来源**是什么？我们之前将业务知识维护到了关系型数据库中,现在需要从关系数据库洗出知识进行向量化
       *   **文档解析**和**文本切分**策略是怎样的？目前是利用llm首先对文章进行摘要生成,然后基于摘要对文章进行分段,对每一段进行向量化
       *   **向量模型**是如何选型的？BERT模型1024维.我们的应用场景在匹配客户问题,也就是问答场景,低维稠密向量能更好地捕捉语义。高维向量适合对语义理解不高,需要高效统计归类的场景.
       *   **检索器**是怎么实现的？目前我们使用了两级,第一级通过对用户输入进行意图识别,识别到意图后将用户输入与属于意图内的知识进行向量匹配,并按照分值由高到低排序,将匹配结果交给我们进行二次加工处理,最终输出答案
       *   如何评估RAG系统的效果？目前无法识别图片,后续可以考虑接入多模态模型,另外幻觉也是有的,其实影响质量的核心是知识质量,在写知识时应该有主题、有结构的编写.
       *   如何平衡检索效率与生成质量?
           *   分层/多阶段检索:第一阶段使用轻量级、高效率的检索器（如 BM25 或稀疏向量）快速筛选候选文档.第二阶段对初筛结果使用更精确但计算成本更高的稠密检索模型.
           *   动态检索数量:不固定返回 top-k 个文档，而是根据查询复杂度或置信度动态调整
           *   检索结果压缩与融合:对检索到的多个文档进行摘要或关键句提取，减少输入长度。使用去重、聚类或信息融合技术，避免冗余信息干扰生成器
           *   缓存索引优化:对高频查询缓存检索结果，避免重复计算
       *   在**语料治理**方面做了哪些工作？数据来源多样,例如邮件数据需要提取QA、船公司pdf文件需要提取文字并使用模型抽取关键信息、对于原始知识文档进行文字提取.